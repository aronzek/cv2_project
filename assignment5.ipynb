{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import imageio\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.models.segmentation import fcn_resnet50\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F_Transforms\n",
    "from torchvision.transforms import ConvertImageDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Fixation Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixationDataset(Dataset):\n",
    "    def __init__(self, root_dir, image_file, fixation_file, image_transform=None, fixation_transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_files = read_text_file(image_file)\n",
    "        self.fixation_files = read_text_file(fixation_file)\n",
    "        self.image_transform = image_transform\n",
    "        self.fixation_transform = fixation_transform\n",
    "        assert len(self.image_files) == len(self.fixation_files), \"lengths of image files and fixation files do not match!\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = imageio.imread(img_name)\n",
    "\n",
    "        fix_name = os.path.join(self.root_dir, self.fixation_files[idx])\n",
    "        fix = imageio.imread(fix_name)\n",
    "\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        if self.fixation_transform:\n",
    "            fix = self.fixation_transform(fix)\n",
    "        \n",
    "        sample = {\"img_name\": self.image_files[idx], \"image\": image, \"fixation\": fix, \"raw_image\": image}\n",
    "        \n",
    "        mean, std = image.mean([1,2]), image.std([1,2])\n",
    "        transform_norm = transforms.Compose([\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "        sample[\"image\"] = transform_norm(image)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeFixationTransform:\n",
    "    def __init__(self):\n",
    "        # initialize any properties if necessary\n",
    "        pass\n",
    "    def __call__(self, x):\n",
    "        # do something to get new_x\n",
    "        new_x = x\n",
    "        return new_x\n",
    "        pass\n",
    "\n",
    "class Eye_Fixation_CNN(nn.Module):\n",
    "    def __init__(self, resnet_model, center_bias):\n",
    "        super().__init__()\n",
    "        self.resnet_model = resnet_model\n",
    "        self.gauss_kernel = torch.nn.Parameter(data=gaussian_kernel(25, 11.2), requires_grad=False)\n",
    "        self.center_bias = torch.nn.Parameter(data=torch.log(center_bias), requires_grad=False)\n",
    "    def forward(self, xb):\n",
    "        \n",
    "        xb = F.conv2d(xb, self.gauss_kernel, padding='same')\n",
    "        xb = self.resnet_model.forward(xb)\n",
    "        xb = xb['out']+self.center_bias\n",
    "        \n",
    "        return xb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pretrained Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_fcn_with_resnet_backbone():\n",
    "    resnet_model = fcn_resnet50(pretrained=False, pretrained_backbone=True, num_classes=1)\n",
    "    for param in resnet_model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "    return resnet_model\n",
    "\n",
    "def read_text_file(filename):\n",
    "    lines = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file: \n",
    "            line = line.strip() #or some other preprocessing\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_type):\n",
    "    image_transform = transforms.Compose([transforms.ToTensor(), EyeFixationTransform()])\n",
    "    fixation_transform = transforms.Compose([transforms.ToTensor(), EyeFixationTransform()])\n",
    "    paths_dict = load_paths()\n",
    "    root_dir = paths_dict['root_dir']\n",
    "    train_images_path = paths_dict['train_images_path']\n",
    "    validation_images_path = paths_dict['validation_images_path']\n",
    "    test_images_path = paths_dict['test_images_path']\n",
    "    train_fixations_path = paths_dict['train_fixations_path']\n",
    "    validation_fixations_path = paths_dict['validation_fixations_path']\n",
    "    logfile_valid = paths_dict['logfile_valid']\n",
    "    logfile_training = paths_dict['logfile_train']\n",
    "    if (data_type == \"train\"):\n",
    "        fixation_ds = FixationDataset(root_dir, train_images_path, train_fixations_path, image_transform, fixation_transform)\n",
    "    elif (data_type == \"valid\"):\n",
    "        fixation_ds = FixationDataset(root_dir, validation_images_path, validation_fixations_path, image_transform, fixation_transform)\n",
    "\n",
    "    samples = []\n",
    "    for sample_index in range(fixation_ds.__len__()):\n",
    "        samples.append(fixation_ds.__getitem__(sample_index))\n",
    "        \n",
    "    fixation_loader = DataLoader(fixation_ds, batch_size=16)\n",
    "    \n",
    "    return fixation_loader\n",
    "\n",
    "def gaussian(window_size: int, sigma: float) -> torch.Tensor:\n",
    "    device, dtype = None, None\n",
    "    if isinstance(sigma, torch.Tensor):\n",
    "        device, dtype = sigma.device, sigma.dtype\n",
    "    x = torch.arange(window_size, device=device, dtype=dtype) - window_size // 2\n",
    "    if window_size % 2 == 0:\n",
    "        x = x + 0.5\n",
    "    gauss = torch.exp(-x.pow(2.0) / (2 * sigma ** 2))\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "def gaussian_kernel(window_size, sigma):\n",
    "    g = gaussian(window_size, sigma)\n",
    "    kernel = torch.matmul(g.unsqueeze(-1), g.unsqueeze(-1).t())\n",
    "    kernel = kernel.expand(3, 3, 25, 25)\n",
    "    return kernel\n",
    "\n",
    "def read_center_bias():\n",
    "    data = np.load(load_paths()['center_bias'])\n",
    "    return torch.tensor(data)\n",
    "\n",
    "def load_paths():\n",
    "    root_dir = \"/data\"\n",
    "    # /Users/cimmykwok/Desktop/CV2/project/data/cv2_training_data\n",
    "    train_images_path = os.path.join(root_dir, 'train_images.txt')\n",
    "    validation_images_path = os.path.join(root_dir, 'val_images.txt')\n",
    "    test_images_path = os.path.join(root_dir, 'test_images.txt')\n",
    "    train_fixations_path = os.path.join(root_dir, 'train_fixations.txt')\n",
    "    validation_fixations_path = os.path.join(root_dir, 'val_fixations.txt')\n",
    "    logfile_valid = os.path.join(root_dir, 'logfile_valid')\n",
    "    logfile_train = os.path.join(root_dir, 'logfilogfile_trainle')\n",
    "    center_bias = os.path.join(root_dir, 'center_bias_density.npy')\n",
    "    checkpoints_path = os.path.join(root_dir, 'checkpoints')\n",
    "    predictions = os.path.join(root_dir, 'predictions')\n",
    "    paths_dict = {'root_dir': root_dir, \n",
    "                  'train_images_path': train_images_path,\n",
    "                  'validation_images_path': validation_images_path,\n",
    "                  'test_images_path': test_images_path,\n",
    "                  'train_fixations_path': train_fixations_path,\n",
    "                  'validation_fixations_path': validation_fixations_path,\n",
    "                  'logfile_valid': logfile_valid,\n",
    "                  'logfile_train': logfile_train,\n",
    "                  'center_bias': center_bias,\n",
    "                  'checkpoints': checkpoints_path,\n",
    "                  'predictions': predictions\n",
    "                  }\n",
    "    return paths_dict\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F_Transforms.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    \n",
    "def visualize_images(inputs, fixations, predictions):\n",
    "    fixations_grid = make_grid(fixations)\n",
    "    show(fixations_grid)\n",
    "    pred_normalized = torch.sigmoid(predictions)\n",
    "    predictions_grid = make_grid(pred_normalized)\n",
    "    show(predictions_grid)\n",
    "\n",
    "def save_network_outputs(predictions, epoch, input):\n",
    "    paths = load_paths()\n",
    "    predictions_path = paths['predictions']\n",
    "\n",
    "    for i, pred in enumerate(predictions):\n",
    "    # for i, pred in predictions:\n",
    "        input_file = re.search(r'\\d+', input[i]).group()\n",
    "        file_path = os.path.join(predictions_path, f\"prediction-{epoch}-{input_file}.png\")\n",
    "        pred = torch.squeeze(pred, 0)\n",
    "        out = ConvertImageDtype(torch.uint8)(torch.sigmoid(pred))\n",
    "        out_np = out.numpy()\n",
    "        imageio.imwrite(file_path, out_np)\n",
    "\n",
    "def log_results(logfile, epoch, train_loss, valid_loss=None):\n",
    "    with open(logfile + '.log', 'a') as f:\n",
    "        f.write(f\"Epoch: {epoch}, Training loss: {train_loss}\\n\")\n",
    "        if valid_loss:\n",
    "            f.write(f\"Epoch: {epoch}, Validation loss: {valid_loss}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data\\\\center_bias_density.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m center_bias \u001b[38;5;241m=\u001b[39m \u001b[43mread_center_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m train_data_loader \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m valid_data_loader \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 43\u001b[0m, in \u001b[0;36mread_center_bias\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_center_bias\u001b[39m():\n\u001b[1;32m---> 43\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcenter_bias\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(data)\n",
      "File \u001b[1;32mc:\\Users\\aronj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    388\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    391\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data\\\\center_bias_density.npy'"
     ]
    }
   ],
   "source": [
    "center_bias = read_center_bias()\n",
    "train_data_loader = load_data(\"train\")\n",
    "valid_data_loader = load_data('valid')\n",
    "#test_data_loader = load_data(\"test\")\n",
    "resnet_model = construct_fcn_with_resnet_backbone()\n",
    "eye_fixation_model = Eye_Fixation_CNN(resnet_model, center_bias)\n",
    "opt = optim.SGD(eye_fixation_model.parameters(), lr=0.1)\n",
    "epochs = 100\n",
    "paths_dict = load_paths()\n",
    "checkpoints_path = paths_dict['checkpoints']\n",
    "logfile_validation_path = paths_dict['logfile_valid']\n",
    "logfile_training_path = paths_dict['logfile_train']\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "eye_fixation_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
